<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="ML with R      The R Bootcamp @ ARC  " />


<title>Representation</title>

<script src="Representation_practical_files/header-attrs-2.20/header-attrs.js"></script>
<script src="Representation_practical_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="Representation_practical_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="Representation_practical_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="Representation_practical_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="Representation_practical_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="Representation_practical_files/navigation-1.1/tabsets.js"></script>
<link href="Representation_practical_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="Representation_practical_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="practical.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">Representation</h1>
<h4 class="author"><font style='font-style:normal'>ML with R</font><br>
<a href='https://therbootcamp.github.io/ML_2023ARC/'><i class='fas fa-clock' style='font-size:.9em;' ></i></a>
<a href='https://therbootcamp.github.io'><i class='fas fa-home' style='font-size:.9em;'></i></a>
<a href='mailto:therbootcamp@gmail.com'><i class='fas fa-envelope' style='font-size: .9em;'></i></a>
<a href='https://www.linkedin.com/company/basel-r-bootcamp/'><i class='fab fa-linkedin' style='font-size: .9em;'></i></a>
<a href='https://therbootcamp.github.io'><font style='font-style:normal'>The
R Bootcamp @ ARC</font></a><br>
<img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/></h4>

</div>


<p align="center">
<img width="100%" src="image/repr.png" margin=0>
</p>
<div id="section" class="section level1 tabset">
<h1 class="tabset"></h1>
<div id="overview" class="section level2">
<h2>Overview</h2>
<p>By the end of this practical you will know how to:</p>
<ol style="list-style-type: decimal">
<li>Extract embeddings from weights.</li>
<li>Extract and visualize similarities between embeddings.</li>
</ol>
</div>
<div id="tasks" class="section level2">
<h2>Tasks</h2>
<div id="a---setup" class="section level3">
<h3>A - Setup</h3>
<ol style="list-style-type: decimal">
<li><p>Open your <code>TheRBootcamp</code> R project.</p></li>
<li><p>Open a new R script. Save it as a new file called
<code>representation_practical.R</code> in the <code>2_Code</code>
folder.</p></li>
<li><p>Using <code>library()</code> load the the packages
<code>tidyverse</code> and <code>keras</code></p></li>
</ol>
<pre class="r"><code># install.packages(&quot;tidyverse&quot;)
# install.packages(&quot;keras&quot;)

# Load packages necessary for this exercise
library(tidyverse)
library(keras)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Now <code>source()</code> the <code>helper_2.R</code> file in your
<code>2_Code</code> folder.</li>
</ol>
<pre class="r"><code># Load helper.R
source(&quot;2_Code/helper_2.R&quot;)</code></pre>
<br>
<p style="font-size:20px;background-color:#6ABA9A;color:white;padding-left:20px" align="left" width="100%">
Part 1: <b>Fashion</b>
</p>
</div>
<div id="b---fit-network" class="section level3">
<h3>B - Fit network</h3>
<ol style="list-style-type: decimal">
<li>Run the code below to load the <code>fashion.RDS</code> dataset as a
new object.</li>
</ol>
<pre class="r"><code># MNIST fashion data
fashion &lt;- readRDS(file = &quot;1_Data/fashion.RDS&quot;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Remind yourself of the contents of the <code>fashion</code> object
using <code>str()</code>.</li>
</ol>
<pre class="r"><code># Inspect contents
str(digit)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Use the code below to run a two-hidden layer neural network
predicting the fashion item.</li>
</ol>
<pre class="r"><code># PREPARATIONS -------

# fashion items
fashion_labels &lt;- c(&#39;T-shirt/top&#39;,&#39;Trouser&#39;,&#39;Pullover&#39;,&#39;Dress&#39;,&#39;Coat&#39;, 
                   &#39;Sandal&#39;,&#39;Shirt&#39;,&#39;Sneaker&#39;,&#39;Bag&#39;,&#39;Ankle boot&#39;)

# split digit  train
c(fashion_train_images, fashion_train_items) %&lt;-% fashion$train

# split digit  test
c(fashion_test_images, fashion_test_items) %&lt;-% fashion$test

# reshape images
fashion_train_images_serialized &lt;- array_reshape(fashion_train_images, c(nrow(fashion_train_images), 784))
fashion_test_images_serialized &lt;- array_reshape(fashion_test_images, c(nrow(fashion_test_images), 784))

# rescale images
fashion_train_images_serialized &lt;- fashion_train_images_serialized / 255
fashion_test_images_serialized &lt;- fashion_test_images_serialized / 255

# expand criterion
fashion_train_items_onehot &lt;- to_categorical(fashion_train_items, 10)
fashion_test_items_onehot &lt;- to_categorical(fashion_test_items, 10)

# MODELING -------

# initialize deepnet
net &lt;- keras_model_sequential()

# add layer
net %&gt;% 
  layer_dense(input_shape = 784, units = 256, activation = &quot;relu&quot;) %&gt;% 
  layer_dense(units = 144, activation = &quot;relu&quot;) %&gt;% 
  layer_dense(units = 10, activation = &quot;softmax&quot;)

# model information
summary(net)

# loss, optimizers, &amp; metrics
net %&gt;% compile(
  optimizer = &#39;adam&#39;, 
  loss = &#39;categorical_crossentropy&#39;,
  metrics = c(&#39;accuracy&#39;)
  )

# fit network
net %&gt;% fit(
  x = fashion_train_images_serialized, 
  y = fashion_train_items_onehot,
  epochs = 10
  )</code></pre>
</div>
<div id="c---fashion-embeddings" class="section level3">
<h3>C - Fashion embeddings</h3>
<ol style="list-style-type: decimal">
<li>Use the code below to extract the estimated weights and biases of
the network.</li>
</ol>
<pre class="r"><code># extract weights
weights &lt;- get_weights(net)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Using <code>str()</code> inspect the structure of the
<code>weights</code> object. Do the contents line up with your
expectations?</li>
</ol>
<pre class="r"><code># inspect weights
str(weights)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>There are six elements. Three containing the weights (elements 1,
3, 5) and three containing the biases (elements 2, 4, 6).</p></li>
<li><p>Use the first elements in <code>weights</code> to calculate the
activation patterns, aka the embeddings, at the first layers for the
first <code>1,000</code> fashion items, ignoring the bias and the
activation function. You’ll see, this can be easily done using matrix
multiplication <code>%*%</code>.</p></li>
</ol>
<pre class="r"><code># inspect weights
embedding &lt;- fashion_train_images_serialized[1:1000, ] %*% weights[[1]]</code></pre>
<ol start="5" style="list-style-type: decimal">
<li><p>Assess the dimensionality of <code>embedding</code> using
<code>dim()</code>. Correct numbers of rows and columns?</p></li>
<li><p>Use the <code>plot_embedding()</code> function, which you loaded
earlier when you sourced the <code>helper_2.R</code> file, to visualize
the activations. Rows in the plot will be the <code>1,000</code> fashion
items and columns the <code>256</code> nodes of the embedding at the
first hidden layer. Looks a bit messy right?</p></li>
</ol>
<pre class="r"><code># plot activation
plot_embedding(embedding)</code></pre>
<ol start="7" style="list-style-type: decimal">
<li>To bring some order into matters extract the first <code>1000</code>
fashion items from <code>fashion_train_items</code> and then use those
to order the rows in <code>embedding</code>.</li>
</ol>
<pre class="r"><code># extract fashon items
items &lt;- fashion_train_items[1:1000]

# order activations
embedding &lt;- embedding[order(items), ]</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>Now use again <code>plot_embedding()</code> to plot the embedding.
Things should look a lot clearer. The bands correspond to the different
items, with the <code>0</code>-item (<code>"T-shirt/top"</code>) at the
bottom and the <code>9</code>-item (<code>"Angle boot"</code>) at the
top.</li>
</ol>
</div>
<div id="d---fashion-similarities" class="section level3">
<h3>D - Fashion similarities</h3>
<ol style="list-style-type: decimal">
<li>Use the <code>cosine()</code> function from the
<code>helper_2.R</code> file to determine the similarities between the
fashion item vectors in the embedding. Cosine determines the angle
between the locations of two fashion items in the <code>256</code>
dimensional space that is the embedding. Cosine is algebraically close
to the standard correlation coefficient.</li>
</ol>
<pre class="r"><code># calculate cosine similarities
fashion_cosines &lt;- cosine(embedding)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Now use the <code>plot_cosine</code> function (also from the
<code>helper_2.R</code> file) to plot the matrix of cosine values. The
categories <code>0</code> to <code>9</code> go from top to bottom and
from left to right. Light grey values indicate high cosine similarity,
darker ones low cosine similarity. Try to make sense of the plot.</li>
</ol>
<pre class="r"><code># Plot cosine similarities
plot_cosine(fashion_cosines)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>The cosine similarity plot shows several interesting patterns.
First, items of one item type, as should be, are consistently more
similar to themselves than to other item type. This can be gleaned from
fact that the rectangles in the diagonal are always lightest in their
respective columns. Second, some items types are closer to each other
than others are. This can be gleaned from the fact that there are other
light rectangle off the diagonal. Use the code below to visualize this
information in a more intuitive way using multi-dimensional scaling.
Yes, there is a function ready, <code>plot_cosine_mds()</code>. Try to
make sense of the plot.</li>
</ol>
<pre class="r"><code># calculate cosine similarities
plot_cosine_mds(fashion_cosines, fashion_labels[items[order(items)]+1])</code></pre>
</div>
<div id="e---understanding-prediction-errors" class="section level3">
<h3>E - Understanding prediction errors</h3>
<ol style="list-style-type: decimal">
<li>The cosine mds plot confirmed both the overall good separation of
fashion items, but also that some item types are more similar to each
other than others. Importantly, these patterns should translate into the
errors that the model makes. Use the code below to determine the
confusion matrix for the predictions of the test set. Do the confusions
in prediction line up with the overlap of fashion items in the cosine
mds?</li>
</ol>
<pre class="r"><code># prediction confusion matrix
pred = net %&gt;% predict(fashion_test_images_serialized) %&gt;% k_argmax() %&gt;% as.numeric()
table(fashion_labels[fashion_test_items+1], fashion_labels[pred+1])</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Yes, they do. The biggest prediction errors occur for the types
<code>Coat</code>, <code>Pullover</code>, and <code>Shirt</code>, which
in the cosine mds pretty much sit on top of each other.</li>
</ol>
</div>
<div id="f---optional-deeper-layers" class="section level3">
<h3>F - Optional: Deeper layers</h3>
<ol style="list-style-type: decimal">
<li>Carry out the same analyses as above, however, using the embedding
at the second layer, which are little more complicated to determine, as
the first layer’s biases and the activation function need to be taken
into account.</li>
</ol>
<pre class="r"><code># second layer embedding
relu = function(z) {z[z &lt; 0] = 0; z}
z_1 &lt;- cbind(img_train[1:1000,],1) %*% rbind(weights[[1]], weights[[2]])
a_1 &lt;- t(apply(z_1, 1, relu))
embedding &lt;- a_1 %*% weights[[3]]</code></pre>
<br>
<p style="font-size:20px;background-color:#6ABA9A;color:white;padding-left:20px" align="left" width="100%">
Part 2: <b>Words</b>
</p>
</div>
<div id="g---word-embeddings" class="section level3">
<h3>G - Word embeddings</h3>
<ol style="list-style-type: decimal">
<li>Run the code below to load the <code>capital.RDS</code> dataset as a
new object.</li>
</ol>
<pre class="r"><code># load embeddings
capital &lt;- readRDS(file = &quot;1_Data/capital.RDS&quot;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>The dataset contains a pre-learned embedding on the basis of all of
Wikipedia and a large website corpus. Use <code>rownames()</code>
inspect to words for which embeddings are present.</li>
</ol>
<pre class="r"><code># rownames of capital
rownames(capital)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>The dataset contains embeddings for a bunch of capitals and the
respective countries. Use <code>plot_embedding()</code> to plot the
capital embeddings.</li>
</ol>
<pre class="r"><code># plot capital embedding
plot_embedding(capital)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Not much to see. Maybe a little bit of banding for the pairs of
words belonging to one country, but certainly not much. Calculate the
cosine similarities and plot them.</li>
</ol>
<pre class="r"><code># plot capital
capital_cosine = cosine(capital)
plot_cosine(capital_cosine)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>The cosine plot makes clear that corresponding capitals and
countries are clearly more related to each other than non-corresponding
capitals and countries. However, as before, there are also some high
cosines off-diagonal. Bring more light into the matter by creating
another cosine mds plot.</li>
</ol>
<pre class="r"><code># plot capital
capital_cosine = cosine(capital)
plot_cosine_mds(capital_cosine, rownames(capital_cosine), col = F)</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>The cosine mds plot shows several interesting patterns. First,
countries and capitals are clearly separated, suggesting that countries
among themselves and capitals among themselves are more strongly related
than between them. Second, countries and capitals seem to be the mirror
image of each other, suggesting that there the embedding has
“understood” the link between them. Third, countries and capitals are
clearly arranged according to geography, suggesting that the embedding
has also “understood” the layout of the world.</li>
</ol>
</div>
</div>
<div id="resources" class="section level2">
<h2>Resources</h2>
<div id="cheatsheet" class="section level3">
<h3>Cheatsheet</h3>
<figure>
<center>
<a href="https://github.com/rstudio/cheatsheets/raw/master/keras.pdf">
<img src="image/keras_cheat.png" alt="Trulli" style="width:70%"></a><br>
<font style="font-size:10px"> from
<a href= "https://rstudio.com/resources/cheatsheets/">github.com/rstudio</a></font>
</figure>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
